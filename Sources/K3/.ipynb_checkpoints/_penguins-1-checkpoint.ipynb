{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e1deb9-f203-4938-a7e0-9e3cf708f955",
   "metadata": {},
   "source": [
    "Benötigte Module importieren und Datei laden. Die ersten Zeilen werden ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df77660-8df4-48bb-9c8a-3fce12e5c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rowid species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0      1  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1      2  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2      3  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "3      4  Adelie  Torgersen             NaN            NaN                NaN   \n",
      "4      5  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "\n",
      "   body_mass_g     sex  year  \n",
      "0       3750.0    male  2007  \n",
      "1       3800.0  female  2007  \n",
      "2       3250.0  female  2007  \n",
      "3          NaN     NaN  2007  \n",
      "4       3450.0  female  2007  \n",
      "Empty columns:  Index(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g',\n",
      "       'sex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = \"../Data/penguins.csv\"\n",
    "data = pd.read_csv(path, delimiter=',')\n",
    "\n",
    "print(data.head())\n",
    "print(\"Empty columns: \", data.columns[data.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572a434-7dfc-4fcf-9a1e-ce041a29277f",
   "metadata": {},
   "source": [
    "Daten vorbereiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59f7f64-b877-406b-9821-5b997360fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Biscoe  Dream  Torgersen  bill_length_mm  bill_depth_mm  \\\n",
      "0         0      0          1            39.1           18.7   \n",
      "1         0      0          1            39.5           17.4   \n",
      "2         0      0          1            40.3           18.0   \n",
      "3         0      0          1             NaN            NaN   \n",
      "4         0      0          1            36.7           19.3   \n",
      "..      ...    ...        ...             ...            ...   \n",
      "339       0      1          0            55.8           19.8   \n",
      "340       0      1          0            43.5           18.1   \n",
      "341       0      1          0            49.6           18.2   \n",
      "342       0      1          0            50.8           19.0   \n",
      "343       0      1          0            50.2           18.7   \n",
      "\n",
      "     flipper_length_mm  body_mass_g  female  male  year  \n",
      "0                181.0       3750.0       0     1  2007  \n",
      "1                186.0       3800.0       1     0  2007  \n",
      "2                195.0       3250.0       1     0  2007  \n",
      "3                  NaN          NaN       0     0  2007  \n",
      "4                193.0       3450.0       1     0  2007  \n",
      "..                 ...          ...     ...   ...   ...  \n",
      "339              207.0       4000.0       0     1  2009  \n",
      "340              202.0       3400.0       1     0  2009  \n",
      "341              193.0       3775.0       0     1  2009  \n",
      "342              210.0       4100.0       0     1  2009  \n",
      "343              198.0       3775.0       1     0  2009  \n",
      "\n",
      "[344 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Leere Zellen mit Mittelwerten der Spalten füllen\n",
    "#data['bill_length_mm'] = data['bill_length_mm'].fillna(data['bill_length_mm'].mean())\n",
    "#data['bill_depth_mm'] = data['bill_depth_mm'].fillna(data['bill_depth_mm'].mean())\n",
    "#data['flipper_length_mm'] = data['flipper_length_mm'].fillna(data['flipper_length_mm'].mean())\n",
    "#data['body_mass_g'] = data['body_mass_g'].fillna(data['body_mass_g'].mean())\n",
    "# Leere Zellen mit dem String 'empty' füllen\n",
    "#data['sex'] = data['sex'].fillna(\"empty\")\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Neue Tabelle erzeugen, Spalte für Spalte\n",
    "values = pd.get_dummies(data['island'])\n",
    "values = pd.concat([values, data['bill_length_mm']], axis = 1)\n",
    "values = pd.concat([values, data['bill_depth_mm']], axis = 1)\n",
    "values = pd.concat([values, data['flipper_length_mm']], axis = 1)\n",
    "values = pd.concat([values, data['body_mass_g']], axis = 1)\n",
    "tmp = pd.get_dummies(data['sex'])\n",
    "values = pd.concat([values, tmp], axis = 1)\n",
    "values = pd.concat([values, data['year']], axis = 1)\n",
    "#print(values.corr())\n",
    "print(values)\n",
    "# Welche Spalte soll vorhergesagt werden?\n",
    "col = pd.get_dummies(data['species'])\n",
    "\n",
    "# Aus den zwei Tabellen (eine Tabelle und einer Spalte) vier Tabellen erzeugen\n",
    "train_values, test_values, train_col, test_col = train_test_split(values,col, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224bc75-6906-4849-bd17-45893e5a289a",
   "metadata": {},
   "source": [
    "KNN aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bbff244-7ba0-439f-9c07-921afb0788ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufbau KNN\n",
    "tf.model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu, input_dim=11),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "# Konfiguration des Lernprozesses\n",
    "tf.model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda700c-73d4-4506-8225-1ab33cc6c448",
   "metadata": {},
   "source": [
    "Trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a50fdb9-255c-4438-819e-a8c8d0614aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 11), found shape=(None, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 30 Durchläufe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/zz/c97ldfgn49s6ytw1bfghhzwr0000gn/T/__autograph_generated_filecj50amf1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/metinkaratas/anaconda3/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 11), found shape=(None, 10)\n"
     ]
    }
   ],
   "source": [
    "# 30 Durchläufe\n",
    "tf.model.fit(train_values, train_col, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a81e9-2436-43a7-ab5d-8f1c5dd92677",
   "metadata": {},
   "source": [
    "Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8688ed41-9918-4357-b390-f7fb248d7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 1.4746 - accuracy: 0.7101\n",
      "Test accuracy: 0.7101449370384216\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = tf.model.evaluate(test_values, test_col)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8db76-91ec-4a9c-857f-de58489adaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
