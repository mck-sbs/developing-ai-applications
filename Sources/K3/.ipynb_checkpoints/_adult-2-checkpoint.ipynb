{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e1deb9-f203-4938-a7e0-9e3cf708f955",
   "metadata": {},
   "source": [
    "Benötigte Module importieren und Datei laden. Die ersten Zeilen werden ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df77660-8df4-48bb-9c8a-3fce12e5c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 22:01:48.075381: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education.num  \\\n",
      "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "1   38            Private  215646     HS-grad              9   \n",
      "2   53            Private  234721        11th              7   \n",
      "3   28            Private  338409   Bachelors             13   \n",
      "4   37            Private  284582     Masters             14   \n",
      "\n",
      "        marital.status          occuaption    relationship    race      sex  \\\n",
      "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
      "\n",
      "   capital.gain  capital.loss  hours.per.week  native.country income  \n",
      "0             0             0              13   United-States  <=50K  \n",
      "1             0             0              40   United-States  <=50K  \n",
      "2             0             0              40   United-States  <=50K  \n",
      "3             0             0              40            Cuba  <=50K  \n",
      "4             0             0              40   United-States  <=50K  \n",
      "Empty columns:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "path = \"../Data/adult-2.csv\"\n",
    "data = pd.read_csv(path, delimiter=';')\n",
    "print(data.head())\n",
    "print(\"Empty columns: \", data.columns[data.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507f41d6-76a2-496f-a3b4-486d00ee47ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correlations\n",
      "------------------------------\n",
      "age               1.317378\n",
      "fnlwgt            1.149271\n",
      "education.num     1.430372\n",
      "capital.gain      1.310761\n",
      "capital.loss      1.233836\n",
      "hours.per.week    1.368318\n",
      "dtype: float64\n",
      "Weakest correlations\n",
      "------------------------------\n",
      "fnlwgt            1.149271\n",
      "capital.loss      1.233836\n",
      "capital.gain      1.310761\n",
      "age               1.317378\n",
      "hours.per.week    1.368318\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Ausgabe der Korrelationen\n",
    "correlations = data[data.columns].corr(numeric_only=True)\n",
    "print('All correlations')\n",
    "print('-' * 30)\n",
    "correlations_abs_sum = correlations[correlations.columns].abs().sum()\n",
    "print(correlations_abs_sum)\n",
    "print('Weakest correlations')\n",
    "print('-' * 30)\n",
    "print(correlations_abs_sum.nsmallest(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572a434-7dfc-4fcf-9a1e-ce041a29277f",
   "metadata": {},
   "source": [
    "Daten vorbereiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59f7f64-b877-406b-9821-5b997360fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            age  0   0  education.num  0   0  0   Amer-Indian-Eskimo  \\\n",
      "0      0.837097  5   2             13  2   3  0                    0   \n",
      "1     -0.042640  3   4              9  0   5  1                    0   \n",
      "2      1.057031  3  10              7  2   5  0                    0   \n",
      "3     -0.775755  3   2             13  2   9  5                    0   \n",
      "4     -0.115952  3   5             14  2   3  5                    0   \n",
      "...         ... ..  ..            ... ..  .. ..                  ...   \n",
      "32555 -0.849066  3   0             12  2  12  5                    0   \n",
      "32556  0.103982  3   4              9  2   6  0                    0   \n",
      "32557  1.423589  3   4              9  6   0  4                    0   \n",
      "32558 -1.215624  3   4              9  4   0  3                    0   \n",
      "32559  0.983720  4   4              9  2   3  5                    0   \n",
      "\n",
      "        Asian-Pac-Islander   Black   Other   White   Female   Male  \\\n",
      "0                        0       0       0       1        0      1   \n",
      "1                        0       0       0       1        0      1   \n",
      "2                        0       1       0       0        0      1   \n",
      "3                        0       1       0       0        1      0   \n",
      "4                        0       0       0       1        1      0   \n",
      "...                    ...     ...     ...     ...      ...    ...   \n",
      "32555                    0       0       0       1        1      0   \n",
      "32556                    0       0       0       1        0      1   \n",
      "32557                    0       0       0       1        1      0   \n",
      "32558                    0       0       0       1        0      1   \n",
      "32559                    0       0       0       1        1      0   \n",
      "\n",
      "       hours.per.week   0  \n",
      "0            0.122449  38  \n",
      "1            0.397959  38  \n",
      "2            0.397959  38  \n",
      "3            0.397959   4  \n",
      "4            0.397959  38  \n",
      "...               ...  ..  \n",
      "32555        0.377551  38  \n",
      "32556        0.397959  38  \n",
      "32557        0.397959  38  \n",
      "32558        0.193878  38  \n",
      "32559        0.397959  38  \n",
      "\n",
      "[32560 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Lösche drei Spalten mit kleinen Korrelationswerten\n",
    "# Hier nicht notwendig, da wir neue Tabellen erstellen\n",
    "#data.drop(['fnlwgt','capital.loss','capital.gain'], axis = 1, inplace=True)\n",
    "# Erzeuge Objekte\n",
    "s_scaler = StandardScaler()\n",
    "m_scaler = MinMaxScaler()\n",
    "\n",
    "# Spalten für StandardScaler\n",
    "cols_to_s_scale = ['age']\n",
    "data[cols_to_s_scale] = s_scaler.fit_transform(data[cols_to_s_scale])\n",
    "\n",
    "# Spalten für MinMaxScaler\n",
    "cols_to_m_scale = ['hours.per.week']\n",
    "data[cols_to_m_scale] = m_scaler.fit_transform(data[cols_to_m_scale])\n",
    "\n",
    "\n",
    "values = data['age']\n",
    "\n",
    "temp = data['workclass'].astype('category')\n",
    "temp = temp.cat.codes\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "temp = data['education'].astype('category')\n",
    "temp = temp.cat.codes\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "values = pd.concat([values,data['education.num']], axis = 1)\n",
    "\n",
    "temp = data['marital.status'].astype('category')\n",
    "temp = temp.cat.codes\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "temp = data['occuaption'].astype('category')\n",
    "temp = temp.cat.codes\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "temp = data['relationship'].astype('category')\n",
    "temp = temp.cat.codes\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "temp = pd.get_dummies(data['race'])\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "                           \n",
    "temp = pd.get_dummies(data['sex'])\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "temp = data['hours.per.week']\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "\n",
    "temp = data['native.country'].astype('category')\n",
    "temp = temp.cat.codes\n",
    "values = pd.concat([values,temp], axis = 1)\n",
    "\n",
    "col = pd.get_dummies(data['income'])\n",
    "\n",
    "print(values)\n",
    "\n",
    "\n",
    "# Aus den zwei Tabellen vier Tabellen erzeugen\n",
    "train_values, test_values, train_col, test_col = train_test_split(values,col, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224bc75-6906-4849-bd17-45893e5a289a",
   "metadata": {},
   "source": [
    "KNN aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbff244-7ba0-439f-9c07-921afb0788ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 22:02:03.100610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Aufbau KNN\n",
    "tf.model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu, input_dim=values.shape[1]),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Konfiguration des Lernprozesses\n",
    "tf.model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda700c-73d4-4506-8225-1ab33cc6c448",
   "metadata": {},
   "source": [
    "Trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a50fdb9-255c-4438-819e-a8c8d0614aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "814/814 [==============================] - 2s 1ms/step - loss: 0.4340 - accuracy: 0.7941\n",
      "Epoch 2/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3850 - accuracy: 0.8143\n",
      "Epoch 3/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3756 - accuracy: 0.8191\n",
      "Epoch 4/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3703 - accuracy: 0.8226\n",
      "Epoch 5/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3680 - accuracy: 0.8230\n",
      "Epoch 6/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8243\n",
      "Epoch 7/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3634 - accuracy: 0.8255\n",
      "Epoch 8/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3613 - accuracy: 0.8257\n",
      "Epoch 9/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3593 - accuracy: 0.8289\n",
      "Epoch 10/10\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.3592 - accuracy: 0.8275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ec93e6050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 Durchläufe\n",
    "tf.model.fit(train_values, train_col, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a81e9-2436-43a7-ab5d-8f1c5dd92677",
   "metadata": {},
   "source": [
    "Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8688ed41-9918-4357-b390-f7fb248d7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 842us/step - loss: 0.3717 - accuracy: 0.8259\n",
      "Test accuracy: 0.8258599638938904\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = tf.model.evaluate(test_values, test_col)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f9468-3e54-48cd-9688-fc4f9767733d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
